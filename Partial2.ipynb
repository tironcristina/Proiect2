{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subject 1: MNIST Clustering\n",
    "1.Download the MNIST data set using the code below.\n",
    "2.Ignoring the label normally associated to the dataset, construct a clustering of the data. Your clustering should maximize the v-score measure relative to true data labels ( Paper describing the measure: https://www.aclweb.org/anthology/D07-1043.pdf Implementation available in python: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.v_measure_score.html#sklearn.metrics.v_measure_score ). Note that failing to ignore the labels during training will void your score for this subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import binary\n",
    "\n",
    "some_digit_image = X[1].reshape(28, 28)\n",
    "plt.imshow(some_digit_image, cmap=binary, interpolation=\"nearest\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(len(X),-1)\n",
    "X = X.astype(float) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=KMeans(init='k-means++', n_clusters=100, n_init=10).fit(X)\n",
    "d=c.labels_\n",
    "import numpy as np\n",
    "t = np.zeros(100)\n",
    "a = np.array([10])\n",
    "\n",
    "for j in range(100):\n",
    "    for i in range(70000):\n",
    "        if (z[i] == j): a=np.append(a, [ int(y[i]) ])\n",
    "        if(i==69999): t[j]=np.bincount(a).argmax() \n",
    "        if(i==69999):a = np.array([10])\n",
    "print(metrics.v_measure_score(y, c))\n",
    "d=KMeans(init='random', n_clusters=100, n_init=2).fit(X)\n",
    "c=d.labels_\n",
    "import numpy as np\n",
    "t = np.zeros(100)\n",
    "a = np.array([10])\n",
    "\n",
    "for j in range(100):\n",
    "    for i in range(70000):\n",
    "        if (d[i] == j): a=np.append(a, [ int(y[i]) ])\n",
    "        if(i==69999): t[j]=np.bincount(a).argmax() \n",
    "        if(i==69999):a = np.array([10])\n",
    "                                          \n",
    "for i in range(70000):\n",
    "    d[i]=t[d[i]]\n",
    "print(metrics.v_measure_score(y, z))\n",
    "data=X\n",
    "pca = PCA(n_components=100).fit(data)\n",
    "c=KMeans(init=pca.components_, n_clusters=100, n_init=1).fit(data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Subject 2: Text NewsGroup Classification\n",
    "1.Download the newsgroups data set using the code below.\n",
    "2.Construct a text classifier that predicts the target variable (newsgroups.target) from the input data (newsgroups.data).\n",
    "3.We will evaluate your classifier against a hold-out data set, so be sure to construct a classification function that can receive a single string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os as os\n",
    "import re \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(dir):\n",
    "  files = [dir+\"/\"+f for f in os.listdir(dir)]\n",
    "  texts = []\n",
    "  for file in files:\n",
    "    with open(file,'r') as f:\n",
    "      texts.append(f.read())\n",
    "  return texts\n",
    "\n",
    "def get_imdb_dataset():\n",
    "  positive_train_reviews = read_files(\"./aclImdb/train/pos\")\n",
    "  positive_test_reviews = read_files(\"./aclImdb/test/pos\")\n",
    "  negative_train_reviews = read_files(\"./aclImdb/train/neg\")\n",
    "  negative_test_reviews = read_files(\"./aclImdb/test/neg\")\n",
    "\n",
    "  X = positive_train_reviews+positive_test_reviews+negative_train_reviews+negative_test_reviews\n",
    "  y = np.concatenate([np.ones(len(positive_train_reviews)),\n",
    "                            np.ones(len(positive_test_reviews)),\n",
    "                            np.zeros(len(negative_train_reviews)),\n",
    "                            np.zeros(len(negative_test_reviews))])\n",
    "  \n",
    "  #we'll use some more data for training than it is customary :)\n",
    "  #it's a hard problem\n",
    "  return train_test_split(X,y,test_size=0.2,random_state=7)\n",
    "\n",
    "train_text,test_text,train_sentiment,test_sentiment = get_imdb_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
